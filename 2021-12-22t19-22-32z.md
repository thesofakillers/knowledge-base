---
date: 2021-12-22 19:22:32
title: Autoencoders
id: 2021-12-22t19-22-32z
tags: [uva, uva_dl1]
---

Autoencoders are a class of [Neural Networks](./2021-04-26t18-14-48z.md)
consisting in a feedforward network with input and output dimensions of the same
shape joined by a "bottleneck" hidden layer of smaller dimensionality.

An autoencoder is trained to reconstruct the input samples it is given, with the
effect of learning high quality lower-dimensional representations (read:
encodings) in the process. Autoencoders can therefore be trained in an
unsupervised way.

Autoencoders can be used for

- dimensionality reduction (a-la PCA)
- pre-training
- visualization

It should be noted that while autoencoders _can_ reconstruct the input, they
cannot generate new samples, since the learned latent variable is arbitrary. As
such, we say autoencoders are not probabilistic nor generative models.
