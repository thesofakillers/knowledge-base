---
date: 2021-12-22 15:50:48
title: How do we evaluate GANs?
id: 2021-12-22t15-50-48z
tags: [uva, uva_dl1]
---

When talking about [GANs](./2021-12-22t11-42-44z.md), we have mostly touched on
how to train them and what [difficulties](./2021-12-22t14-40-12z.md) we may run
into.

Once we have trained GAN, how do we evaluate it? What is our goal? Typically, we
wish our output to be of **high quality** (difficult to tell it was generated)
and of **high diversity** (to avoid mode collapse).

Two metrics that can capture these qualities are

- Inception score (IS): This is a score that makes use of a pre-trained deep
  learning classifier, originally the
  [Inception model](./2021-12-21t22-37-46z.md). It has a lowest value of 1.0 and
  a highest value of the number of classes supported by the classification model
  used. The higher the inception score, the better our GAN.
- The FreÃÅchet Inception Distance (FID): which measures the distance between our
  real and generated samples using inception. The lower the distance, the better
  our generative model
