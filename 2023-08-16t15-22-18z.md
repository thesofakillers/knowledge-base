---
date: 2023-08-16 15:22:18
title: Multimodal GCBC - Does it help?
id: 2023-08-16t15-22-18z
tags: [msc_thesis]
---

[GCBC](./2023-07-11t10-17-09z.md)
[fails to generalize to the right goal](./2023-08-10t10-40-36z.md).

In an attempt to diagnose the failure, we
[visualized the trajectory embeddings after a dimensionality reduction](2023-08-15t11-54-42z.md).

Here, we noted that the textual trajectory embeddings from CLIPT (i.e. not
[contextualized](2023-07-11t11-38-00z.md)) were quite disentangled, unlike the
visual embeddings on which misgeneralizing GCBC was trained on.

We ask ourselves if the more disentangled structure of the textual trajectory
embeddings could help by providing the supervision necessary for GCBC
generalization.

We therefore adapt the GCBC code a little bit such that when training, for each
batch, we randomly train on textual or visual trajectory embeddings, effectively
training on multimodal data.

We present the results of our training below

INSERT TABLE HERE

![](gcbc_mm_gmg_multitask_new.png)

Unfortunately it appears that the multimodality does not help. Based on the
[embeddings visualizations](2023-08-15t11-54-42z.md), this could be because the
embedding for "key" is closer to the color embeddings than to the other object
embeddings, so that our model is not properly building a representation for
"objectness" and "colorness", making it difficult to generalize.
