---
date: 2023-07-12 13:29:12
title: "Fully trained CCLIPT evaluation: A sanity check sanity check"
id: 2023-07-12t13-29-12z
tags: [msc_thesis]
---

We previously tried verifying if [CCLIPT](./2023-07-11t11-38-00z.md) was just
[memorizing the shared context](./2023-07-11t12-32-21z.md) between textual and
visual trajectories. As pointed out in a final note, we were unsure whether the
results of this ablation were valid, since we had trained CCLIPT in two stages,
the first of which was in [CLIPT](./2023-07-10t16-36-37z.md) mode, i.e. without
any shared context.

So, after [fully training CCLIPT from scratch](./2023-07-12t13-47-41z.md), we
repeated the ablation study: we [evaluate](./2023-07-10t18-29-00z.md) CCLIPT in
its normal state, and then evaluate its performance when setting the second half
of the input to its encoders to 0. If the performance stays the same, something
is wrong: CCLIPT is learning to just ignore the second half of the inputs.

Before the ablation

![full cclipt eval](./images/full_cclipt_eval.pdf)

```plaintext
Accuracy@1: 1.000
Accuracy@3: 1.000
Accuracy@5: 1.000
Accuracy@10: 1.000
Accuracy@20: 1.000
Accuracy@50: 1.000
```

After the ablation

![full cclipt eval ablated](./images/full_cclipt_eval_ablated.pdf)

```plaintext
Accuracy@1: 0.000
Accuracy@3: 0.008
Accuracy@5: 0.008
Accuracy@10: 0.027
Accuracy@20: 0.086
Accuracy@50: 0.207
```

We see a large accuracy drop and the disappearance of the diagonal. This is good
news, even when fully training from scratch in a single stage, CCLIPT is not
ignoring the second halves of the inputs.
