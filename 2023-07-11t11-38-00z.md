---
date: 2023-07-11 11:38:00
title: "CCLIPT: Closing the gap between textual and visual performance of GCBC"
id: 2023-07-11t11-38-00z
tags: [msc_thesis]
---

We can leverage the fact that [GCBC](./2023-07-11t10-17-09z.md) is trained
exclusively on visual trajectory representations to make adjustments to the
textual trajectory representations and re-[evaluate](./2023-07-11t10-52-26z.md)
without having to re-train.

This for instance can be used to close the performance gap between textual and
visual representations. We can fine-tune the textual encoder of
[CLIPT](./2023-07-10t16-36-37z.md) to produce representations of the visual
encoder, keeping the visual encoder frozen throughout.

We however do not wish to directly fine-tune the textual encoder, the
[LM](./2021-12-20t11-06-56z.md), as this would be expensive and may lead to loss
of generality.

Instead, we add a MLP head and fine tune that. To mirror what happens with the
visual encoder, we provide "context" in the form of the current state. So the
textual trajectory representations are now the MLP combination of the
representation of the current state and the representation of the text. We refer
to this as **contextualized CLIPT** or **CCLIPT**.

After fine-tuning CCLIPT, we find the following performance on GCBC evaluation:

![GCBC eval with CCLIPT](cclipt_gcbc_eval.png)

|       | Textual Success Rate | Visual Success Rate |
| ----- | -------------------- | ------------------- |
| count | 34.000000            | 34.000000           |
| mean  | 0.352647             | 0.354118            |
| std   | 0.191854             | 0.199729            |
| min   | 0.090000             | 0.050000            |
| 25%   | 0.225000             | 0.202500            |
| 50%   | 0.310000             | 0.320000            |
| 75%   | 0.417500             | 0.510000            |
| max   | 0.860000             | 0.810000            |

We find that the gap has been closed almost perfectly.
