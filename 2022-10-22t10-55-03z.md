---
date: 2022-10-22 10:55:03
title: Temporal Difference learning in RL
id: 2022-10-22t10-55-03z
tags: [uva, uva_rl]
---

Temporal Difference (TD) learning is a class of
[value-based learning](./2022-10-22t10-34-46z.md) methods that uses
[bootstrapping](./2022-10-22t10-56-02z.md) to update estimates based in part on
previous estimates and experience.

This is similar to [dynamic programming](./2022-10-21t17-13-39z.md) but, does
not require knowledge of the [MDP](./2022-10-21t12-12-18z.md) dynamics,
similarly to [Monte Carlo methods](./2022-10-22t10-38-24z.md). Unlike MC
methods, TD methods make updates at a step level rather than at an episode
level.
