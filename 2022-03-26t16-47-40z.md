---
date: 2022-03-26 16:47:40
title: Cohen's Kappa
id: 2022-03-26t16-47-40z
tags: [uva, uva_ir1]
---

Cohen's kappa is a statistic used for determining the agreement between multiple
assessments of categorical items. Mathematically, to measure the kappa $\kappa$
between two assessments, we have

$$
\kappa = \frac{P(A) - P(E)}{1 - P(E)},
$$

where $P(A)$ is the probability that the assessments agree, and $P(E)$ is the
probability that the assessments agree due to chance.

For more than two assessments, we simply average the pair-wise coefficients.

The resulting kappa should be in the range between 0.67 and 0.8 for the
agreement to be considered acceptable.
