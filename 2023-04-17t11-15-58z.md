---
date: 2023-04-17 11:15:58
title: LISDM requires (partially) solving the grounding problem
id: 2023-04-17t11-15-58z
---

[Language-informed sequential decision making (LISDM)](./2023-04-11t15-01-36z.md)
will typically require (partially) solving the
[grounding problem](./2021-12-19t17-55-55z.md). I say partially because I use
the term in the [ML sense](./2023-04-17t11-31-04z.md): for narrow enough LISDM
solutions, simply ensuring representations of the same concept from a few
modalities are similar may be enough.

But why does the grounding problem need addressing? This is because to be able
to use language to make decisions in a given environment, the meaning of the
words needs to be properly tied to the environment. Otherwise, the language
vectors may as well simply be random vectors.

For instance, if we are trying to use language to make decisions in a
restaurant, we need to ensure that the vector for the word "apple" is similar to
the vector of an apple in the restaurant. This is because we want to be able to
use the word "apple" to refer to the apple in the restaurant, and not to some
other apple in some other restaurant.
