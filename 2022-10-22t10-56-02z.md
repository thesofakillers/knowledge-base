---
date: 2022-10-22 10:56:02
title: (n-step) Bootstrapping in RL
id: 2022-10-22t10-56-02z
tags: [uva, uva_rl]
---

_Bootstrapping_ refers to the technique of using previous estimates to make new
estimates.

In [Reinforcement learning](./2022-10-20t15-15-55z.md), bootstrapping is used in
[dynamic programming](./2022-10-21t17-13-39z.md),
[temporal difference learning](./2022-10-22t10-55-03z.md) and can be generalised
into the concept of _n-step bootstrapping_.

With _n-step bootstrapping_, we can generalise both TD learning and
[Monte Carlo methods](./2022-10-22t10-38-24z.md), simply defining a
hyperparameter $n$ that determines how many steps ahead we consider when making
our updates.

This is done by generalising the [return](./2022-10-21t11-04-35z.md):

$$
G_{t:t+n} \dot{=} R_{t+1} + \gamma R_{t+2} + \cdots +
                    \gamma^{n-1} R_{t+n} + \gamma^n V_{t+n-1}(S_{t+n})
$$

Resulting in the following [update](./2022-10-22t17-36-28z.md):

$$
V_{t+n-1}(S_t) \dot{=}
    V_{t+n-1}(S_t) + \alpha \left[ G_{t:t+n} - V_{t+n-1}(S_t) \right].
$$

This can be applied to any of the algorithms covered in MC and TD learning.
