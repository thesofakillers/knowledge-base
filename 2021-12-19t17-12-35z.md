---
date: 2021-12-19 17:12:35
title: Vector Mixture Models for Compositional Distributional Semantics
id: 2021-12-19t17-12-35z
tags: [uva, uva_nlp1]
---

In vector mixture models, the composition of the vectors of a phrase is either
addition or multiplication.

This has a few limitations:

1. Addition or multiplication make these models commutative, causing them to
   fail to account for word order which can carry additional meaning.
2. VMM are not very well suited for modelling function words such as
   conjunctions and prepositions, since function words are typically very well
   distributed throughout the data (they co-occur with a large variety of words)
   resulting in very flat, non-specific distributions that are difficult to
   learn. The result is that VMM would class sentences such as "lice and dogs"
   and "lice on dogs" as very similar when they are not.
3. VMM cannot deal well with recursion, a property of natural language by which
   there is no fixed limit to the number of modifiers used in a grammatically
   and semantically valid phrase. With VMM, particularly those using
   multiplication as composition, recursion can cause particular components of
   the resulting vectors to explode, dwarfing other features which may have been
   of use
