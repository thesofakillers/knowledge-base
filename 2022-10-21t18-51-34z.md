---
date: 2022-10-21 18:51:34
title: Policy Iteration in RL
id: 2022-10-21t18-51-34z
tags: [uva, uva_rl]
---

We can alternate [policy improvement](./2022-10-21t17-34-21z.md) and
[policy evaluation](./2022-10-21t17-23-28z.md) to iteratively improve a policy
until it converges to the optimal policy.

Because [finite MDPs](./2022-10-21t12-12-18z.md) have a finite set of
deterministic policies, convergence to the optimal
[value function](./2022-10-21t10-45-34z.md) and
[optimal policy](./2022-10-21t12-52-19z.md) is guaranteed in a finite number of
steps.

This process of alternating policy evaluation and policy improvement is called
_policy iteration_.
