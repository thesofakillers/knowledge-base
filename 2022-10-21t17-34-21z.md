---
date: 2022-10-21 17:34:21
title: Policy Improvement (Theorem) in RL
id: 2022-10-21t17-34-21z
tags: [uva, uva_rl]
---

In [dynamic programming](./2022-10-21t17-13-39z.md), the _policy improvement
theorem_ states that for two deterministic policies $\pi$ and $\pi'$, if

$$
q_\pi(s, \pi'(s)) \geq v_\pi(s) \quad \forall s,
$$

then $\pi'$ is at least as good as $\pi$, i.e.

$$
v_{\pi'}(s) \geq v_\pi(s) \quad \forall s.
$$

We can use the policy improvement theorem to guide us in how to change our
policy so to improve overall performance. We understand that if we act greedily
at a given state, we will take the action that maximizes the expected return at
that state. We can apply this reasoning to all states and obtain a greedy
policy:

$$
v_{\pi'}(s) = \arg\max_a q_\pi(s, a) \quad \forall s.
$$

This policy takes the best action in the short term, one step ahead of the
current step. By design and the policy improvement theorem, the greedy policy is
at least an improvement to the current policy.

The process of making a new policy that improves on an original policy, by
making it greedy with respect to the value function of the original policy, is
called policy improvement. Policy improvement always gives a strictly better
policy, unless the original policy is already optimal.
