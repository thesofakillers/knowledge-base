---
date: 2023-07-13 22:55:21
title: Runtimes, Optimization and Profiling for my MSc Thesis
id: 2023-07-13t22-55-21z
tags: [msc_thesis]
---

The following serves as a rough _[[knowledge dump]]_ on the runtimes,
optimization and profiling in my [MSc thesis](./2023-07-10t14-32-02z.md).
Runtimes are **bolded**

## Runtimes and Optimization

- The fastest I have been able to run [GCBC](./2023-07-11t10-17-09z.md) training
  without [precomputed CLIP embeddings](./2023-07-13t00-50-10z.md) and without
  [rolling trajectories](./2023-07-11t12-33-17z.md) is around **4 hours per
  epoch**, including two validation epochs (I validate twice per epoch).
  - using precomputed CLIP embeddings should speed things up
  - using rolling trajectories initially slowed things down, but after
    eliminating a for-loop in the forward pass should be roughly of the same
    speed
  - The optimization necessary for this involved copying the zipped data from
    the `/scratch-shared/` storage to the local `/scratch-node/` storage, which
    offers much faster disk-read speeds.
    - Copying the 166 GB .zip file takes **3 minutes**.
    - Unzipping takes roughly **20 minutes**.
  - Shared memory also speeds things up (albeit marginally), and preparation of
    shared memory is near instant on the `/scratch-node/` storage space.
- It takes roughly **8 hours** to pre-compute the CLIP embeddings for the entire
  task_D_D [[CALVIN]] dataset, including the saving process. Most of this is for
  the images, since these dominate the dataset.
- [GCBC Evaluation](./2023-07-11t10-52-26z.md) without rolling trajectories
  takes roughly 5 hours. _With_ rolling trajectories it takes ~36 hours at best
  and _much_ more at worse.
  - ~~We could try addressing this by implementing batched rollouts...~~
    - We have implemented batched rollouts
      - [x] Try running evaluation for with batched rollouts for speedup.
      - it doesn't work
  - Much smarter: run this with a SLURM array

## Profiling

Sometimes I need to debug why my code was running slower suddenly, or determine
which parts of my code are bottlenecked to tackle for optimization.

### How I profile

To do this I make simple profiling scripts, and then run them with
[cProfile](https://docs.python.org/3/library/profile.html). For example, see
[profile-gcbc.py](https://github.com/thesofakillers/thesis/blob/main/src/nlgoals/run/profile-gcbc.py)
or
[prof_dataloader.py](https://github.com/thesofakillers/thesis/blob/main/src/nlgoals/data/calvin/repo/code/prof_dataloader.py).
These scripts produce a `.prof` file, which I then convert to `.dot` using
[gprof2dot](https://github.com/jrfonseca/gprof2dot). The `.dot` file contains
[DOT graph](https://www.graphviz.org/doc/info/lang.html) language specification
for visualizing the call graph of the profiled script with
[GraphViz](https://www.graphviz.org/). I use this
[GraphViz Online](https://dreampuf.github.io/GraphvizOnline/) tool to render.

In steps:

1. Make a script with a `main()` function that calls the function you want to
   profile a few times.
   - At the bottom of the script, have an `if __name__=="__main__"` block that
     calls `cProfile.run("main()", filename='output.prof')`.
2. Run the script. This will produce `output.prof`
3. Convert `output.prof` to `.dot` format:

   ```terminal
   gprof2dot -f pstats output.prof -o output.dot
   ```

4. Copy the `.dot` file contents to your clipboard somehow.

   ```terminal
   dot output.dot | pbcopy
   ```

5. Paste the contents on GraphvizOnline and visualize the call graph.
6. Locate the bottlenecks from the call graph. They will be covered in
   red/orange/yellow.

### Some profiling results

- I found that the transforms take roughly the same amount of time as reading
  the files from the disk.
- I was able to debug a sudden decrease in speed, finding that the CLIPProcessor
  was suddenly slower in a newer version of huggingface.
  - I also found an
    i[ssue complaining about the speed of the CLIPProcessor in general](https://github.com/huggingface/transformers/issues/13991),
    and pointing me to a faster implementation using torchvision
- I ensured that my rolling trajectory forward pass was as optimized as
  possible.
