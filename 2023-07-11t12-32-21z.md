---
date: 2023-07-11 12:32:21
title:
  Is CCLIPT just relying on the shared context between textual and visual
  trajectories?
id: 2023-07-11t12-32-21z
tags: [msc_thesis]
---

In [CCLIPT](./2023-07-11t11-38-00z.md), the first halves of the input to the MLP
encoder heads for textual and visual trajectories are identical: in both cases
we encode the current state and concatenate it with the encoding of the final
state or text depending on the kind of trajectory.

CCLIPT is then trained by vanilla [[constrastive loss]], to reduce the distance
between pairs of related visual and textual trajectories and increase it
otherwise. Because half of the input is shared, perhaps the encoders are simply
learning to ignore the second half of the input, which is where most of the
information is contained. This could be causing the
[large gap in performance when eliminating suggestive starts in GCBC evaluation](./2023-07-11t12-12-49z.md).

To investigate, we perform [intrinsic evaluation](./2023-07-10t18-29-00z.md) of
CCLIPT before and after setting the second half of the inputs to 0. If CCLIPT is
not simply ignoring the second half, we should notice a large drop in
performance. If there is no drop in performance, then this is indicative that
CCLIPT is just ignoring the second half.

Below, we report the results of this investigate

<!-- TODO -->

WIP
