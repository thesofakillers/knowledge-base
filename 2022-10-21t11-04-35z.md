---
date: 2022-10-21 11:04:35
title: Returns in Reinforcement Learning
id: 2022-10-21t11-04-35z
tags: [uva, uva_rl]
---

In [RL](./2022-10-20t15-15-55z.md), the _return_ is defined as the total reward
the agent accumulates in future time-steps, starting from a given state.

Mathematically, this is defined as

$$
G_t = R_{t+1} + R_{t+2} + \cdots = \sum_{k=0}^\infty \gamma^k R_{t+k+1}.
$$

This definition generalises to both
[episodic and continuing tasks](./2022-10-21t11-26-04z.md), as we introduce the
discounting factor $\gamma$ so that the summation converges even for infinite
sequences. The discounting factor is a number between 0 and 1, and has the
effect of reducing the importance of future rewards. For episodic tasks, the
discounting factor can be set to 1.
